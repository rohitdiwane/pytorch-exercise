{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPe0PfvvQtHgYXIzzy9EO4t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. Design model (input size, output size, forward_pass)\n","2. construct loss and optimizer\n","3. training\n","  - forward pass: compute prediction\n","  - backward pass: gradients\n","  - update weights"],"metadata":{"id":"dpQ1IrbQZSg7"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","# f = w * x         # linera eq.\n","\n","# f = 2 * x\n","x = torch.tensor([1,2,3,4], dtype=torch.float32)\n","y = torch.tensor([2,4,6,8], dtype=torch.float32)\n","\n","w = torch.tensor(0.0, dtype= torch.float32, requires_grad=True)\n","\n","\n","# model prediction\n","def forward(x):\n","  return w * x\n","\n","print(f'prediction before training : f(5) = {forward(5):.3f}')\n","\n","# training\n","\n","learning_rate = 0.01\n","n_iters = 10\n","loss = nn.MSELoss()\n","optimizers = torch.optim.SGD([w], lr=learning_rate)\n","\n","for epoch in range(n_iters):\n","  # prediction = forward pass\n","  y_pred = forward(x)\n","\n","  # loss\n","  l = loss(y, y_pred)\n","\n","  # gradients = backward pass\n","  l.backward() # dl/dw\n","\n","  # update weights\n","  optimizers.step()\n","\n","  # zero gradients\n","  optimizers.zero_grad\n","\n","  if epoch % 2 == 0:  # printing every 100 steps\n","    print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n","\n","print(f'prediction after training : f(5) = {forward(5):.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gp3eMN5CYc9Q","executionInfo":{"status":"ok","timestamp":1704303866186,"user_tz":-330,"elapsed":10,"user":{"displayName":"Rohit Diwane","userId":"16455405406727471674"}},"outputId":"2be27c2e-5065-4807-fbb2-8a6a7ba4b027"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["prediction before training : f(5) = 0.050\n","epoch 1: w = 0.308500, loss = 29.70074844\n","epoch 3: w = 1.583841, loss = 9.73460770\n","epoch 5: w = 3.099514, loss = 1.02331984\n","epoch 7: w = 3.980218, loss = 20.78469467\n","epoch 9: w = 3.717345, loss = 29.96049500\n","prediction after training : f(5) = 15.892\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","# f = w * x         # linera eq.\n","\n","# f = 2 * x\n","x = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n","y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n","\n","x_test = torch.tensor([5], dtype=torch.float32) # prediction of 5th point\n","\n","n_samples, n_features = x.shape\n","print(n_samples, n_features)\n","\n","input_size = n_features\n","output_size = n_samples\n","\n","model = nn.Linear(input_size, output_size)\n","\n","print(f'prediction before training : f(5) = {model(x_test)[0].item():.3f}')   # item is used for only 1 value\n","\n","# training\n","\n","learning_rate = 0.01\n","n_iters = 100\n","loss = nn.MSELoss()\n","optimizers = torch.optim.SGD(model.parameters(), lr=learning_rate) # we dont have weights so we used model.parameters()\n","\n","for epoch in range(n_iters):\n","  # prediction = forward pass\n","  y_pred = model(x)\n","\n","  # loss\n","  l = loss(y, y_pred)\n","\n","  # gradients = backward pass\n","  l.backward() # dl/dw\n","\n","  # update weights\n","  optimizers.step()\n","\n","  # zero gradients\n","  optimizers.zero_grad\n","\n","  if epoch % 10 == 0:  # printing every 10 steps\n","    [w, b] = model.parameters()\n","    print(f'epoch {epoch+1}: w = {w[0][0].item():3f}, loss = {l:.8f}') # dont wants to print tensor so, used [][].items\n","\n","print(f'prediction after training : f(5) = {model(x_test)[0].item():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ur_fBVHUanzk","executionInfo":{"status":"ok","timestamp":1704305050943,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit Diwane","userId":"16455405406727471674"}},"outputId":"fd837518-6ffe-414d-d465-0ad3ae4fb4ec"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["4 1\n","prediction before training : f(5) = 3.115\n","epoch 1: w = 0.638191, loss = 28.84622002\n","epoch 11: w = 2.668592, loss = 8.77673531\n","epoch 21: w = 2.206472, loss = 7.15176392\n","epoch 31: w = 0.667539, loss = 29.04600525\n","epoch 41: w = 2.643463, loss = 5.19932938\n","epoch 51: w = 2.502033, loss = 10.88814926\n","epoch 61: w = 0.804458, loss = 28.08846283\n","epoch 71: w = 2.657470, loss = 2.44230747\n","epoch 81: w = 2.807347, loss = 15.02069187\n","epoch 91: w = 0.951815, loss = 26.14513588\n","prediction after training : f(5) = 11.360\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2zBT78DAcOpq"},"execution_count":null,"outputs":[]}]}